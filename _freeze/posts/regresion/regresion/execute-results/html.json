{
  "hash": "60bb98ff6670f125510df0832baa2269",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Regresión lineal múltiple\"\ndescription: \n  Árboles y regresión\nauthor: \"Eduardo Aragón\"\ndate: \"2026-01-28\"\ncategories: [Regresión, Múltiple,Multicolinealidad,Normalidad,Homocedasticidad]\nimage: \"regresion.jpg\"\n---\n\nEn este post vamos a trabajar con uno de los datasets que viene en R base, pues nos va a permitir realizar un caso de regresión lineal múltiple. Para ello vamos a usar el conjunto de datos `trees` el cual contiene las mediciones del diámetro, la altura y el volumen de la madera para 31 árboles de cereza negra que han sido talados. Empezamos cargando los datos y viendo las variables que podemos encontrar.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(trees)\nnames(trees)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Girth\"  \"Height\" \"Volume\"\n```\n\n\n:::\n:::\n\n\nPor tanto, observamos que tenemos 3 variables con las que vamos a trabajar.\n\n-   `Girth`: Diámetro del árbol en pulgadas. Será nuestra variable dependiente.\n\n-   `Height`: Altura del árbol en pies.\n\n-   `Volume`: Volumen de la madera en pies cúbicos.\n\nPodemos ver como están definidos los datos:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(trees)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Girth Height Volume\n1   8.3     70   10.3\n2   8.6     65   10.3\n3   8.8     63   10.2\n4  10.5     72   16.4\n5  10.7     81   18.8\n6  10.8     83   19.7\n```\n\n\n:::\n:::\n\n\nUn paso importante es verificar si la base de datos tiene datos faltantes. Una manera sencilla de comprobarlo es sumando los posibles elementos `NA` que tenga la propia base, por lo que si la suma sale 0 no habrá valores de este tipo.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(is.na(trees))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0\n```\n\n\n:::\n:::\n\n\nPor tanto, vemos que no hay datos faltantes. Por comodidad, trabajaremos con las variables después de usar `attach`, y como no hay valores faltantes no hace falta guardar la base original en otro objeto por si lo necesitáramos más adelante.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nattach(trees)\n```\n:::\n\n\n# Regresión lineal múltiple\n\nPara obtener la estimación del modelo lineal de regresión hacemos uso de la función `lm` y mostramos sus resultados.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo <- lm(Volume ~ Girth + Height, data = trees)\nsummary(modelo)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Volume ~ Girth + Height, data = trees)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.4065 -2.6493 -0.2876  2.2003  8.4847 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -57.9877     8.6382  -6.713 2.75e-07 ***\nGirth         4.7082     0.2643  17.816  < 2e-16 ***\nHeight        0.3393     0.1302   2.607   0.0145 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.882 on 28 degrees of freedom\nMultiple R-squared:  0.948,\tAdjusted R-squared:  0.9442 \nF-statistic:   255 on 2 and 28 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\nEn la salida de `summary` obtenemos la estimación de los coeficientes del modelo en la columna `Estimate`, siendo cada uno de ellos significativos al 5%, pues sus p-valores que podemos encontrar en la columna `Pr(>|t|)` son todos menores que 0.05. También obtenemos otras medidas de interés como que $R^2$=0.948, por lo que el 94.8% del diámetro del árbol es explicado tanto por la altura como por el volumen de la madera.\n\nUna vez obtenido el modelo es el momento de ver si se verifican las hipótesis asociadas al mismo.\n\n# Hipótesis básicas del modelo\n\nDentro de las hipótesis del modelo vamos a estudiar si existe multicolinealidad entre las variables, si existe normalidad al estudiar los residuos y si la varianza es constante para los errores (homocedasticidad). En este caso no se estudia la autocorrelación, pues no se trata de datos temporales.\n\n## Multicolinealidad\n\nEl estudio de la multicolinealidad (que las variables estén fuertemente correlacionadas entre sí) lo vamos a hacer de diferentes maneras. Empezamos observando la propia matriz de correlaciones.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nX = cbind(Girth,Height)\ncor(X)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           Girth    Height\nGirth  1.0000000 0.5192801\nHeight 0.5192801 1.0000000\n```\n\n\n:::\n:::\n\n\nVemos que las dos variables explicativas tienen una correlación cercana a 0.52, por lo que al ser dicha correlación menor a 0.7, como normalmente se suele indicar en teoría, podemos decir que dicha relación no es fuerte, que es justo lo que andamos buscando. Otra manera sería calculando el determinante de dicha matriz, donde al estar más próximo su valor a 1 es buen indicio de que la correlación no es fuerte.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndet(cor(X))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.7303482\n```\n\n\n:::\n:::\n\n\nOtro elemento a tener en cuenta es el factor de inflación de la varianza (VIF), el cual indica el incremento de la varianza estimada del coeficiente de regresión de una variable explicativa como consecuencia de la colinealidad con las demás variables. Para obtenerla se usa la orden `vif` del paquete `car`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(car)\nvif(modelo)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Girth  Height \n1.36921 1.36921 \n```\n\n\n:::\n:::\n\n\nComo ambos valores son menores que 5, podemos decir que hay multicolinealidad baja o aceptable, por lo que seguiremos sin problema.\n\nPor último, vamos a estudiar el Número de Condición. Para ello podemos hacer uso de la función `CNs` de la librería `multiColl`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"multiColl\")\ncte = array(1,length(Volume))\nCNs(cbind(cte,X))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$`Condition Number without intercept`\n[1] 10.02612\n\n$`Condition Number with intercept`\n[1] 32.17813\n\n$`Increase (in percentage)`\n[1] 68.84181\n```\n\n\n:::\n:::\n\n\nAl usar el Número de Condición, debemos comprobar si los valores son mayores que 30, pues eso implicaría un caso de multicolinealidad no esencial preocupante. En este caso, cuando no incluimos la constante dicho valor es cercano a 10, pero al incluirlo aumenta notablemente la colinealidad, pues ese valor es mayor que 30.\n\nA continuación se presenta una manera de poder corregir este inconveniente, que no es más que restar a cada una de sus variables su propia media. Se puede comprobar que ahora el Número de Condición, con constante o sin ella, es menor que 2 lo que es un claro indicio de no multicolinealidad.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nGirth_c <- Girth-mean(Girth)\nHeight_c <- Height-mean(Height)\nX_centrado <- cbind(Girth_c,Height_c)\n\nX_final <- cbind(1, X_centrado)\nCNs(X_final) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$`Condition Number without intercept`\n[1] 1.777759\n\n$`Condition Number with intercept`\n[1] 1.777759\n\n$`Increase (in percentage)`\n[1] -2.498028e-14\n```\n\n\n:::\n:::\n\n\nPor otro lado, podría ser interesante comparar el primer modelo con uno que tenga las variables centradas.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"memisc\")\nmodelo_c <- lm(Volume ~ Girth_c + Height_c)\nmtable(modelo,modelo_c)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCalls:\nmodelo: lm(formula = Volume ~ Girth + Height, data = trees)\nmodelo_c: lm(formula = Volume ~ Girth_c + Height_c)\n\n======================================\n                 modelo    modelo_c   \n--------------------------------------\n  (Intercept)  -57.988***  30.171***  \n                (8.638)    (0.697)    \n  Girth          4.708***             \n                (0.264)               \n  Height         0.339*               \n                (0.130)               \n  Girth_c                   4.708***  \n                           (0.264)    \n  Height_c                  0.339*    \n                           (0.130)    \n--------------------------------------\n  R-squared      0.948      0.948     \n  N             31         31         \n======================================\n  Significance: *** = p < 0.001;   \n                ** = p < 0.01;   \n                * = p < 0.05  \n```\n\n\n:::\n:::\n\n\nVemos que el único valor que cambia es el asociado a la constante. Mientras que la interpretación de los coeficientes es la misma que en el modelo sin centrar, ahora cuando ambas variables independientes valgan su media, el volumen esperado de un árbol sera 30.171 pies cúbicos. Visto esto, a partir de ahora vamos a usar el modelo centrado.\n\n## Normalidad\n\nEl siguiente supuesto que vamos a probar es el de normalidad. Para ello empleamos, sobre los residuos del modelo centrado, los test de Shapiro-Wilks y Kolmogorov-Smirnov-Lilliefors.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshapiro.test(residuals(modelo_c))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  residuals(modelo_c)\nW = 0.97431, p-value = 0.644\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"nortest\")\nlillie.test(residuals(modelo_c))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tLilliefors (Kolmogorov-Smirnov) normality test\n\ndata:  residuals(modelo_c)\nD = 0.085485, p-value = 0.8161\n```\n\n\n:::\n:::\n\n\nMediante ambos test obtenemos un p-valor superior a 0.05, por lo que no tendríamos evidencias estadísticas para rechazar la hipótesis nula de normalidad.\n\nTambién podríamos observar como se ajustan los residuos a la línea teórica de un QQ-Plot. En este caso, vemos que la gran mayoría se ajustan bien, aunque es cierto, que en el extremo superior derecho existen ciertos valores más altos de lo que se espera. Sin embargo, el rechazo de los test anteriores era muy claro, por lo que decimos que los residuos son normales.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqqnorm(residuals(modelo_c))\nqqline(residuals(modelo_c))\n```\n\n::: {.cell-output-display}\n![](regresion_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n## Homocedasticidad\n\nPara comprobar que exista homocedasticidad vamos a hacer uso de una serie de test que nos permitan verificarla. Podríamos plantear el siguiente contraste de hipótesis: $$\n\\begin{cases}\nH_0:\\text{Existe homocedasticidad}\\\\\nH_1:\\text{Existe heterocedasticidad}\n\\end{cases}\n$$\n\nTest de White:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(skedastic)\nwhite(modelo_c)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 5\n  statistic p.value parameter method       alternative\n      <dbl>   <dbl>     <dbl> <chr>        <chr>      \n1      15.5 0.00378         4 White's Test greater    \n```\n\n\n:::\n:::\n\n\nTest de Breusch-Pagan:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lmtest)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: zoo\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'zoo'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n```\n\n\n:::\n\n```{.r .cell-code}\nbptest(modelo_c)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tstudentized Breusch-Pagan test\n\ndata:  modelo_c\nBP = 2.4681, df = 2, p-value = 0.2911\n```\n\n\n:::\n:::\n\n\nTest de Goldfeld-Quandt:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngqtest(modelo_c, fraction=1/3, order.by=Girth_c) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tGoldfeld-Quandt test\n\ndata:  modelo_c\nGQ = 11.003, df1 = 8, df2 = 7, p-value = 0.002439\nalternative hypothesis: variance increases from segment 1 to 2\n```\n\n\n:::\n\n```{.r .cell-code}\ngqtest(modelo_c, fraction=1/3, order.by=Height_c) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tGoldfeld-Quandt test\n\ndata:  modelo_c\nGQ = 3.7927, df1 = 8, df2 = 7, p-value = 0.04788\nalternative hypothesis: variance increases from segment 1 to 2\n```\n\n\n:::\n:::\n\n\nLos distintos test nos dan conclusiones totalmente distintas. Por un lado el test de Breusch-Pagan tiene un p-valor superior a 0.05, por lo que es el único que no rechaza la homocedasticidad. Los test restantes rechazan ambos $H_0$ en el contraste anterior por lo que podríamos decir que hay un problema de heterocedasticidad. Además, el test de Goldfeld-Quandt rechaza igualmente si los datos se ordenan por cualquiera de las variables explicativas.\n\nPor tanto, decimos que hay un problema de heterocedasticidad. Ante tal situación, podríamos aplicar una corrección de heterocedasticidad dando más peso a alguna de estas variables, pero no se obtienen mejorías.\n\nPor ello, vamos a plantear un nuevo modelo donde vamos a transformar la variable asociada al volumen mediante logaritmos.\n\n# Modelo de regresión con variable dependiente logarítmica\n\nCreamos el nuevo modelo mediante `lm`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelo_l <- lm(log(Volume) ~ Girth_c + Height_c)\nsummary(modelo_l)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = log(Volume) ~ Girth_c + Height_c)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.177279 -0.086019 -0.009928  0.058914  0.170011 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 3.272732   0.017378 188.323  < 2e-16 ***\nGirth_c     0.145290   0.006587  22.057  < 2e-16 ***\nHeight_c    0.016385   0.003244   5.051 2.41e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.09676 on 28 degrees of freedom\nMultiple R-squared:  0.9684,\tAdjusted R-squared:  0.9662 \nF-statistic: 429.7 on 2 and 28 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\nObtenemos que todos los parámetros son significativamente distintos de cero, pues los p-valores son claramente menores que cualquier nivel de significación arbitrario. Por tanto, consideramos este modelo a falta de ser validado.\n\nEn este caso pasamos directamente a la verificación de la normalidad y homocedasticidad. No tiene sentido volver a estudiar la multicolinealidad pues es el mismo proceso que hicimos anteriormente cuando decidimos trabajar con las variables centradas, ya que estudiamos la matriz de coeficientes y sigue siendo la misma.\n\n## Normalidad\n\nAplicamos una vez más tanto Shapiro-Wilks como K-S-Lilliefors.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshapiro.test(residuals(modelo_l))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  residuals(modelo_l)\nW = 0.97144, p-value = 0.5594\n```\n\n\n:::\n\n```{.r .cell-code}\nlillie.test(residuals(modelo_l))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tLilliefors (Kolmogorov-Smirnov) normality test\n\ndata:  residuals(modelo_l)\nD = 0.10869, p-value = 0.4616\n```\n\n\n:::\n:::\n\n\nEn ambos casos tenemos un p-valor superior a 0.05, por lo que no tenemos evidencias para rechazar la normalidad.\n\n## Homocedasticidad\n\nAplicamos los test de White, Breusch-Pagan y Goldfeld-Quandt.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwhite(modelo_l)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 5\n  statistic p.value parameter method       alternative\n      <dbl>   <dbl>     <dbl> <chr>        <chr>      \n1      5.49   0.241         4 White's Test greater    \n```\n\n\n:::\n\n```{.r .cell-code}\nbptest(modelo_l)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tstudentized Breusch-Pagan test\n\ndata:  modelo_l\nBP = 2.2859, df = 2, p-value = 0.3189\n```\n\n\n:::\n\n```{.r .cell-code}\ngqtest(modelo_l, fraction=1/3, order.by=Girth_c) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tGoldfeld-Quandt test\n\ndata:  modelo_l\nGQ = 2.6514, df1 = 8, df2 = 7, p-value = 0.1082\nalternative hypothesis: variance increases from segment 1 to 2\n```\n\n\n:::\n\n```{.r .cell-code}\ngqtest(modelo_l, fraction=1/3, order.by=Height_c) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tGoldfeld-Quandt test\n\ndata:  modelo_l\nGQ = 2.2815, df1 = 8, df2 = 7, p-value = 0.1469\nalternative hypothesis: variance increases from segment 1 to 2\n```\n\n\n:::\n:::\n\n\nAhora así obtenemos un p-valor superior a 0.05 con cada uno de los test, por lo que no tendríamos evidencias para rechazar la hipótesis nula de homocedasticidad.\n\nPor tanto, como este último modelo verifica todas las hipótesis asociadas, lo consideramos como el modelo a elegir. De este modelo podemos decir:\n\n-   `Intercept`: El valor esperado de `log(Volume)` cuando las variables explicativas están centradas es 3.272732.\n\n-   `Girth_c`: Por cada unidad de aumento en esta variable, se espera que `Volume` aumente aproximadamente un 15.64% ($e^{0.1453}$-1=0.1563864).\n\n-   `Height_c`: Por cada unidad de aumento en esta variable, `Volume` se espera que aumente aproximadamente un 1.65% ($e^{0.016385}$-1=0.01651997).\n",
    "supporting": [
      "regresion_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}