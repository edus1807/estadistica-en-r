[
  {
    "objectID": "posts/regresion/regresion.html",
    "href": "posts/regresion/regresion.html",
    "title": "Regresión lineal múltiple",
    "section": "",
    "text": "En este post vamos a trabajar con uno de los datasets que viene en R base, pues nos va a permitir realizar un caso de regresión lineal múltiple. Para ello vamos a usar el conjunto de datos trees el cual contiene las mediciones del diámetro, la altura y el volumen de la madera para 31 árboles de cereza negra que han sido talados. Empezamos cargando los datos y viendo las variables que podemos encontrar.\ndata(trees)\nnames(trees)\n\n[1] \"Girth\"  \"Height\" \"Volume\"\nPor tanto, observamos que tenemos 3 variables con las que vamos a trabajar.\nPodemos ver como están definidos los datos:\nhead(trees)\n\n  Girth Height Volume\n1   8.3     70   10.3\n2   8.6     65   10.3\n3   8.8     63   10.2\n4  10.5     72   16.4\n5  10.7     81   18.8\n6  10.8     83   19.7\nUn paso importante es verificar si la base de datos tiene datos faltantes. Una manera sencilla de comprobarlo es sumando los posibles elementos NA que tenga la propia base, por lo que si la suma sale 0 no habrá valores de este tipo.\nsum(is.na(trees))\n\n[1] 0\nPor tanto, vemos que no hay datos faltantes. Por comodidad, trabajaremos con las variables después de usar attach, y como no hay valores faltantes no hace falta guardar la base original en otro objeto por si lo necesitáramos más adelante.\nattach(trees)"
  },
  {
    "objectID": "posts/regresion/regresion.html#multicolinealidad",
    "href": "posts/regresion/regresion.html#multicolinealidad",
    "title": "Regresión lineal múltiple",
    "section": "Multicolinealidad",
    "text": "Multicolinealidad\nEl estudio de la multicolinealidad (que las variables estén fuertemente correlacionadas entre sí) lo vamos a hacer de diferentes maneras. Empezamos observando la propia matriz de correlaciones.\n\nX = cbind(Girth,Height)\ncor(X)\n\n           Girth    Height\nGirth  1.0000000 0.5192801\nHeight 0.5192801 1.0000000\n\n\nVemos que las dos variables explicativas tienen una correlación cercana a 0.52, por lo que al ser dicha correlación menor a 0.7, como normalmente se suele indicar en teoría, podemos decir que dicha relación no es fuerte, que es justo lo que andamos buscando. Otra manera sería calculando el determinante de dicha matriz, donde al estar más próximo su valor a 1 es buen indicio de que la correlación no es fuerte.\n\ndet(cor(X))\n\n[1] 0.7303482\n\n\nOtro elemento a tener en cuenta es el factor de inflación de la varianza (VIF), el cual indica el incremento de la varianza estimada del coeficiente de regresión de una variable explicativa como consecuencia de la colinealidad con las demás variables. Para obtenerla se usa la orden vif del paquete car.\n\nlibrary(car)\nvif(modelo)\n\n  Girth  Height \n1.36921 1.36921 \n\n\nComo ambos valores son menores que 5, podemos decir que hay multicolinealidad baja o aceptable, por lo que seguiremos sin problema.\nPor último, vamos a estudiar el Número de Condición. Para ello podemos hacer uso de la función CNs de la librería multiColl.\n\nlibrary(\"multiColl\")\ncte = array(1,length(Volume))\nCNs(cbind(cte,X))\n\n$`Condition Number without intercept`\n[1] 10.02612\n\n$`Condition Number with intercept`\n[1] 32.17813\n\n$`Increase (in percentage)`\n[1] 68.84181\n\n\nAl usar el Número de Condición, debemos comprobar si los valores son mayores que 30, pues eso implicaría un caso de multicolinealidad no esencial preocupante. En este caso, cuando no incluimos la constante dicho valor es cercano a 10, pero al incluirlo aumenta notablemente la colinealidad, pues ese valor es mayor que 30.\nA continuación se presenta una manera de poder corregir este inconveniente, que no es más que restar a cada una de sus variables su propia media. Se puede comprobar que ahora el Número de Condición, con constante o sin ella, es menor que 2 lo que es un claro indicio de no multicolinealidad.\n\nGirth_c &lt;- Girth-mean(Girth)\nHeight_c &lt;- Height-mean(Height)\nX_centrado &lt;- cbind(Girth_c,Height_c)\n\nX_final &lt;- cbind(1, X_centrado)\nCNs(X_final) \n\n$`Condition Number without intercept`\n[1] 1.777759\n\n$`Condition Number with intercept`\n[1] 1.777759\n\n$`Increase (in percentage)`\n[1] -2.498028e-14\n\n\nPor otro lado, podría ser interesante comparar el primer modelo con uno que tenga las variables centradas.\n\nlibrary(\"memisc\")\nmodelo_c &lt;- lm(Volume ~ Girth_c + Height_c)\nmtable(modelo,modelo_c)\n\n\nCalls:\nmodelo: lm(formula = Volume ~ Girth + Height, data = trees)\nmodelo_c: lm(formula = Volume ~ Girth_c + Height_c)\n\n======================================\n                 modelo    modelo_c   \n--------------------------------------\n  (Intercept)  -57.988***  30.171***  \n                (8.638)    (0.697)    \n  Girth          4.708***             \n                (0.264)               \n  Height         0.339*               \n                (0.130)               \n  Girth_c                   4.708***  \n                           (0.264)    \n  Height_c                  0.339*    \n                           (0.130)    \n--------------------------------------\n  R-squared      0.948      0.948     \n  N             31         31         \n======================================\n  Significance: *** = p &lt; 0.001;   \n                ** = p &lt; 0.01;   \n                * = p &lt; 0.05  \n\n\nVemos que el único valor que cambia es el asociado a la constante. Mientras que la interpretación de los coeficientes es la misma que en el modelo sin centrar, ahora cuando ambas variables independientes valgan su media, el volumen esperado de un árbol sera 30.171 pies cúbicos. Visto esto, a partir de ahora vamos a usar el modelo centrado."
  },
  {
    "objectID": "posts/regresion/regresion.html#normalidad",
    "href": "posts/regresion/regresion.html#normalidad",
    "title": "Regresión lineal múltiple",
    "section": "Normalidad",
    "text": "Normalidad\nEl siguiente supuesto que vamos a probar es el de normalidad. Para ello empleamos, sobre los residuos del modelo centrado, los test de Shapiro-Wilks y Kolmogorov-Smirnov-Lilliefors.\n\nshapiro.test(residuals(modelo_c))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(modelo_c)\nW = 0.97431, p-value = 0.644\n\n\n\nlibrary(\"nortest\")\nlillie.test(residuals(modelo_c))\n\n\n    Lilliefors (Kolmogorov-Smirnov) normality test\n\ndata:  residuals(modelo_c)\nD = 0.085485, p-value = 0.8161\n\n\nMediante ambos test obtenemos un p-valor superior a 0.05, por lo que no tendríamos evidencias estadísticas para rechazar la hipótesis nula de normalidad.\nTambién podríamos observar como se ajustan los residuos a la línea teórica de un QQ-Plot. En este caso, vemos que la gran mayoría se ajustan bien, aunque es cierto, que en el extremo superior derecho existen ciertos valores más altos de lo que se espera. Sin embargo, el rechazo de los test anteriores era muy claro, por lo que decimos que los residuos son normales.\n\nqqnorm(residuals(modelo_c))\nqqline(residuals(modelo_c))"
  },
  {
    "objectID": "posts/regresion/regresion.html#homocedasticidad",
    "href": "posts/regresion/regresion.html#homocedasticidad",
    "title": "Regresión lineal múltiple",
    "section": "Homocedasticidad",
    "text": "Homocedasticidad\nPara comprobar que exista homocedasticidad vamos a hacer uso de una serie de test que nos permitan verificarla. Podríamos plantear el siguiente contraste de hipótesis: \\[\n\\begin{cases}\nH_0:\\text{Existe homocedasticidad}\\\\\nH_1:\\text{Existe heterocedasticidad}\n\\end{cases}\n\\]\nTest de White:\n\nlibrary(skedastic)\nwhite(modelo_c)\n\n# A tibble: 1 × 5\n  statistic p.value parameter method       alternative\n      &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;      \n1      15.5 0.00378         4 White's Test greater    \n\n\nTest de Breusch-Pagan:\n\nlibrary(lmtest)\n\nLoading required package: zoo\n\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\nbptest(modelo_c)\n\n\n    studentized Breusch-Pagan test\n\ndata:  modelo_c\nBP = 2.4681, df = 2, p-value = 0.2911\n\n\nTest de Goldfeld-Quandt:\n\ngqtest(modelo_c, fraction=1/3, order.by=Girth_c) \n\n\n    Goldfeld-Quandt test\n\ndata:  modelo_c\nGQ = 11.003, df1 = 8, df2 = 7, p-value = 0.002439\nalternative hypothesis: variance increases from segment 1 to 2\n\ngqtest(modelo_c, fraction=1/3, order.by=Height_c) \n\n\n    Goldfeld-Quandt test\n\ndata:  modelo_c\nGQ = 3.7927, df1 = 8, df2 = 7, p-value = 0.04788\nalternative hypothesis: variance increases from segment 1 to 2\n\n\nLos distintos test nos dan conclusiones totalmente distintas. Por un lado el test de Breusch-Pagan tiene un p-valor superior a 0.05, por lo que es el único que no rechaza la homocedasticidad. Los test restantes rechazan ambos \\(H_0\\) en el contraste anterior por lo que podríamos decir que hay un problema de heterocedasticidad. Además, el test de Goldfeld-Quandt rechaza igualmente si los datos se ordenan por cualquiera de las variables explicativas.\nPor tanto, decimos que hay un problema de heterocedasticidad. Ante tal situación, podríamos aplicar una corrección de heterocedasticidad dando más peso a alguna de estas variables, pero no se obtienen mejorías.\nPor ello, vamos a plantear un nuevo modelo donde vamos a transformar la variable asociada al volumen mediante logaritmos."
  },
  {
    "objectID": "posts/regresion/regresion.html#normalidad-1",
    "href": "posts/regresion/regresion.html#normalidad-1",
    "title": "Regresión lineal múltiple",
    "section": "Normalidad",
    "text": "Normalidad\nAplicamos una vez más tanto Shapiro-Wilks como K-S-Lilliefors.\n\nshapiro.test(residuals(modelo_l))\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuals(modelo_l)\nW = 0.97144, p-value = 0.5594\n\nlillie.test(residuals(modelo_l))\n\n\n    Lilliefors (Kolmogorov-Smirnov) normality test\n\ndata:  residuals(modelo_l)\nD = 0.10869, p-value = 0.4616\n\n\nEn ambos casos tenemos un p-valor superior a 0.05, por lo que no tenemos evidencias para rechazar la normalidad."
  },
  {
    "objectID": "posts/regresion/regresion.html#homocedasticidad-1",
    "href": "posts/regresion/regresion.html#homocedasticidad-1",
    "title": "Regresión lineal múltiple",
    "section": "Homocedasticidad",
    "text": "Homocedasticidad\nAplicamos los test de White, Breusch-Pagan y Goldfeld-Quandt.\n\nwhite(modelo_l)\n\n# A tibble: 1 × 5\n  statistic p.value parameter method       alternative\n      &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;      \n1      5.49   0.241         4 White's Test greater    \n\nbptest(modelo_l)\n\n\n    studentized Breusch-Pagan test\n\ndata:  modelo_l\nBP = 2.2859, df = 2, p-value = 0.3189\n\ngqtest(modelo_l, fraction=1/3, order.by=Girth_c) \n\n\n    Goldfeld-Quandt test\n\ndata:  modelo_l\nGQ = 2.6514, df1 = 8, df2 = 7, p-value = 0.1082\nalternative hypothesis: variance increases from segment 1 to 2\n\ngqtest(modelo_l, fraction=1/3, order.by=Height_c) \n\n\n    Goldfeld-Quandt test\n\ndata:  modelo_l\nGQ = 2.2815, df1 = 8, df2 = 7, p-value = 0.1469\nalternative hypothesis: variance increases from segment 1 to 2\n\n\nAhora así obtenemos un p-valor superior a 0.05 con cada uno de los test, por lo que no tendríamos evidencias para rechazar la hipótesis nula de homocedasticidad.\nPor tanto, como este último modelo verifica todas las hipótesis asociadas, lo consideramos como el modelo a elegir. De este modelo podemos decir:\n\nIntercept: El valor esperado de log(Volume) cuando las variables explicativas están centradas es 3.272732.\nGirth_c: Por cada unidad de aumento en esta variable, se espera que Volume aumente aproximadamente un 15.64% (\\(e^{0.1453}\\)-1=0.1563864).\nHeight_c: Por cada unidad de aumento en esta variable, Volume se espera que aumente aproximadamente un 1.65% (\\(e^{0.016385}\\)-1=0.01651997)."
  },
  {
    "objectID": "posts/descriptiva/descriptiva.html",
    "href": "posts/descriptiva/descriptiva.html",
    "title": "Estadística Descriptiva",
    "section": "",
    "text": "En esta ocasión vamos a hacer un ejemplo completo de como debería empezarse a trabajar con unos datos, arrancando desde un estudio descriptivo de los mismos. Para este ejemplo únicamente vamos a trabajar con una variable, pero este análisis podría hacerse de manera bidimensional o con más variables.\nLo primero es determinar la base de datos con la que vamos a trabajar. Para ello se ha seleccionado penguins perteneciente a la librería palmerpenguins.\nlibrary(palmerpenguins)\ndatos&lt;-penguins\nUna vez cargados los datos se puede usar la función names para ver el nombre de las variables, mientras que con la orden attach se agiliza la manipulación de nuestro data.frame pues permite referenciar las columnas de este directamente. Hay que tener cuidado con esta última función pues en caso de que exista otra variable con el mismo nombre en tu entorno de R pueden existir conflictos.\nnames(datos)\n\n[1] \"species\"           \"island\"            \"bill_length_mm\"   \n[4] \"bill_depth_mm\"     \"flipper_length_mm\" \"body_mass_g\"      \n[7] \"sex\"               \"year\"             \n\nattach(datos)\nTambién podemos ver como se encuentra estructurada la base de datos mostrando las primeras filas de la misma:\nhead(datos)\n\n# A tibble: 6 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\nPor tanto vemos que tenemos ocho variables, de las cuales nos vamos a centrar en las cuantitativas, puesto que las otras se entiende a que se refieren:\nEn este ejemplo nos focalizaremos en la variable asociada a la masa corporal. Sin embargo, todo el análisis siguiente puede ser replicado para caulquiera de las otras tres variables descritas.\nDicho esto es el momento de mirar si tenemos datos faltantes en la muestra. Puesto que si disponemos de varios valores de este tipo y una muestra considerablemente grande, se crea una nueva base de datos sin ellos para no perder la original y obtener los siguientes resultados a partir de ella.\nsum(is.na(datos))\n\n[1] 19\n\nnrow(datos)\n\n[1] 344\n\ndatos2&lt;-na.omit(datos)\nmasa_corporal&lt;-datos2$body_mass_g\nAntes de obtener las medidas descriptivas típicas, como son las de posición, dispersión o forma, puede ser interesante ver como se encuentran los datos desde el punto de vista gráfico."
  },
  {
    "objectID": "posts/descriptiva/descriptiva.html#histograma",
    "href": "posts/descriptiva/descriptiva.html#histograma",
    "title": "Estadística Descriptiva",
    "section": "Histograma",
    "text": "Histograma\nPuesto que disponemos de datos continuos, podemos comenzar representando un histograma de la masa corporal.\n\nminimo = min(masa_corporal)\nmaximo = max(masa_corporal)\nrango = maximo - minimo\nintervalos = 9 # número de intervalos de igual amplitud que quiero crear\nhist(masa_corporal,breaks = seq(minimo,maximo,rango/intervalos),freq = FALSE,col=\"royalblue\",xlab=\"Masa corporal\",ylab = \"Porcentaje\",main = \"Histograma de la masa corporal\")\n\n\n\n\n\n\n\n\nCon esta gráfica ya podemos hacernos una idea de que el valor más frecuente para el peso corporal de los pingüinos está entre los 3.5kg y los 4kg. También se aprecia un claro sesgo hacía la derecha, lo que se traduce en aunque la mayoría de los pingüinos tienen pesos bajos o medios, existe un menor grupo de estos que posee pesos significativamente más altos. Esto último también nos indica que la media será mayor que la mediana, pero eso lo veremos más adelante."
  },
  {
    "objectID": "posts/descriptiva/descriptiva.html#diagrama-de-caja-y-bigotes",
    "href": "posts/descriptiva/descriptiva.html#diagrama-de-caja-y-bigotes",
    "title": "Estadística Descriptiva",
    "section": "Diagrama de caja y bigotes",
    "text": "Diagrama de caja y bigotes\nOtro gráfico esencial es el diagrama de caja y bigotes, también conocido como diagrama box-Whisker. La importancia de este gráfico reside en que nos permite ver con precisión la posible existencia de valores atípicos u outliers (aquellos datos que presentan un comportamiento anómalo al resto). En caso de que existieran habría que investigar que causas pueden estar provocándolos, como datos mal recogidos o introducidos, o si se tratan de valores plausibles, por lo que dependerá del investigador en cuestión la manera de tratarlos.\n\nboxplot(masa_corporal,ylab=\"Masa corporal\",main=\"Diagrama de caja y bigotes\",col = \"magenta3\")\n\n\n\n\n\n\n\n\nEn este caso solo nos interesa la masa corporal, pero podría ser interesante como se comporta dicha variable en función de otras como las cualitativas que veíamos al principio. Por ejemplo, podemos ver como se comporta el peso dependiendo de la especie. Además se añade una leyenda que puede ser útil para otros proyectos.\n\nespecies&lt;-datos2$species\nboxplot(masa_corporal~especies,col = c(\"springgreen3\",\"cadetblue2\",\"tomato2\"),ylab=\"Masa corporal\",main=\"Diagrama de caja y bigotes\")\nlegend(\"topleft\",legend = levels(especies),fill = c(\"springgreen3\", \"cadetblue2\", \"tomato2\"),title = \"Especie\")\n\n\n\n\n\n\n\n\nPodemos ver como para la especie Chinstrap si existen valores atípicos, pero como lo estamos estudiando de manera conjunta con el resto de especies no entraremos más en detalle."
  },
  {
    "objectID": "posts/descriptiva/descriptiva.html#curva-de-lorenz",
    "href": "posts/descriptiva/descriptiva.html#curva-de-lorenz",
    "title": "Estadística Descriptiva",
    "section": "Curva de Lorenz",
    "text": "Curva de Lorenz\nEl último gráfico que se presenta es la curva de Lorenz.\n\nlibrary(ineq) # para usarlo hay que cargarlo en la memoria\n    plot(Lc(masa_corporal), col=\"darkred\", lwd=2)   \n\n\n\n\n\n\n\n\nViendo la gráfica podemos decir que la distribución de la masa corporal es bastante equitativa entre los pingüinos, pues la curva está bastante próxima a la diagonal. Por tanto, no hay unos pingüinos que concentran mayoritariamente todo el peso al igual que no existen individuos extremadamente delgados comparados con el resto, siendo la distribución bastante equitativa.\nPara terminar los gráficos se recomienda la web RCHARTS donde se podrá encontrar bastante información sobre distintas paletas de colores o la librería ggplot2 muy utilizada para las visualizaciones de datos."
  },
  {
    "objectID": "posts/descriptiva/descriptiva.html#estadísticos-de-posición",
    "href": "posts/descriptiva/descriptiva.html#estadísticos-de-posición",
    "title": "Estadística Descriptiva",
    "section": "Estadísticos de posición",
    "text": "Estadísticos de posición\nSon aquellos que describen dónde se concentran los valores de la variable. La manera de obtenerlos en R es la siguiente:\n\n# Número de observaciones\nn &lt;- length(masa_corporal)\n\n# Media aritmética\nmedia&lt;-mean(masa_corporal)\nmedia\n\n[1] 4207.057\n\n# Mediana (la función var calcula la cuasivarianza)\nmedian(masa_corporal)\n\n[1] 4050\n\n# Moda\nmoda &lt;- as.numeric(names(which.max(table(masa_corporal))))\nmoda\n\n[1] 3800\n\n# Quartil 1\nquantile(masa_corporal, probs = 0.25) \n\n 25% \n3550 \n\n# Quartil 3\nquantile(masa_corporal, probs = 0.75) \n\n 75% \n4775"
  },
  {
    "objectID": "posts/descriptiva/descriptiva.html#medidas-de-dispersión",
    "href": "posts/descriptiva/descriptiva.html#medidas-de-dispersión",
    "title": "Estadística Descriptiva",
    "section": "Medidas de dispersión",
    "text": "Medidas de dispersión\nSon aquellas que miden la variabilidad o dispersión de los datos. La manera de obtenerlos en R es la siguiente:\n\n# Varianza (la función var calcula la cuasivarianza)\nvarianza &lt;- ((n - 1) / n) * var(masa_corporal)\nvarianza\n\n[1] 646425.4\n\n# Desviación típica\ndesv_tip &lt;- sqrt(varianza)\ndesv_tip\n\n[1] 804.0059\n\n# Mínimo\nmin(masa_corporal) \n\n[1] 2700\n\n# Máximo\nmax(masa_corporal)\n\n[1] 6300\n\n# Rango total\nrango &lt;- maximo - minimo\nrango\n\n[1] 3600\n\n# Coeficiente de variación\nCV &lt;- desv_tip / abs(media)\nCV\n\n[1] 0.1911089"
  },
  {
    "objectID": "posts/descriptiva/descriptiva.html#medidas-de-forma",
    "href": "posts/descriptiva/descriptiva.html#medidas-de-forma",
    "title": "Estadística Descriptiva",
    "section": "Medidas de forma",
    "text": "Medidas de forma\nSon aquellas que indican la forma de la distribución, concretamente consideramos el coeficiente de asimetría y curtosis. Se pueden obtener mediante la librería moments.\n\nlibrary(moments)\n\n# Asimetría\nskewness(masa_corporal)\n\n[1] 0.4701162\n\n# Curtosis\nkurtosis(masa_corporal) - 3\n\n[1] -0.7404859"
  },
  {
    "objectID": "posts/descriptiva/descriptiva.html#índice-de-gini",
    "href": "posts/descriptiva/descriptiva.html#índice-de-gini",
    "title": "Estadística Descriptiva",
    "section": "Índice de Gini",
    "text": "Índice de Gini\nEs una medida de concentración que permite evaluar la desigualdad en la distribución de la variable. Se puede calcular mediante la función ineq perteneciente a la librería con mismo nombre.\n\nlibrary(ineq)\nineq(masa_corporal, type = \"Gini\")\n\n[1] 0.1084586"
  },
  {
    "objectID": "posts/descriptiva/descriptiva.html#conclusiones-generales",
    "href": "posts/descriptiva/descriptiva.html#conclusiones-generales",
    "title": "Estadística Descriptiva",
    "section": "Conclusiones generales",
    "text": "Conclusiones generales\nCon las medidas se confirman algunas conclusiones que vimos mediante los gráficos como que la media es mayor que la mediana, pues la distribución tenía asimetría a la derecha, quedando esto a su vez remarcado gracias al coeficiente de asimetría, el cual es &gt; 0. Por otro lado, el coeficiente de curtosis es &lt; 0, lo que indica que la distribución de la masa corporal es más achatada que la de una distribución normal. Por último, el índice de Gini es muy próximo a 0, por lo que la distribución es muy equitativa como se comprobó con la curva de Lorenz."
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "Perfil Profesional\nEstadístico con formación sólida en análisis de datos y modelado cuantitativo, capaz de transformar información compleja en conclusiones claras y útiles para la toma de decisiones.\n\n\nFormación\n\nMáster en Técnicas Cuantitativas en Gestión Empresarial  Universidad de Granada 2025-Presente (en curso)\nGrado en Estadística  Universidad de Granada 2021-2025\nInglés: B1  Cambridge English: Preliminary (PET) 2018\n\n\n\nHabilidades\n\nSoftware y herramientas: R, Rstudio, SPSS, Python, Stata, Excel.\nAnálisis de datos y técnicas estadísticas: inferencia estadística, modelos lineales, ANOVA, series temporales, visualización de datos.\nInterpretación y comunicación de resultados.\n\n\n\nProyectos Académicos de Interés\nTrabajo de Fin de Grado: Análisis de la Varianza con medidas repetidas | 2024-2025\n\nEstudio teórico del ANOVA con medidas repetidas y aplicación práctica sobre datos reales de memorias RRAM (industria de semiconductores).\nAnálisis del comportamiento de la intensidad de corriente al fijar el voltaje suministrado y aplicar un número determinado de pulsos en intervalos regulares.\n\nAnálisis de una serie temporal sobre nacimientos mensuales en Andalucía | 2024\n\nAnálisis de datos del INE correspondientes al período 2012–2022 para estudiar la evolución de los nacimientos en Andalucía.\n\n\n\nModelización y predicción de la serie temporal para estimar los valores del año siguiente.\n\nAnálisis de una encuesta sobre percepción de la ciencia y la tecnología (basada en el CIS) | 2023\n\nReplicación parcial de un cuestionario del CIS para evaluar actitudes hacia la ciencia y la tecnología mediante Google Forms.\nLimpieza, procesamiento e imputación de datos, aplicando técnicas estadísticas para identificar tendencias y relaciones entre variables sociodemográficas y nivel de interés científico.\n\nAnálisis de la satisfacción de clientes de una aerolínea | 2024\n\nEvaluación de la existencia de asociaciones entre la satisfacción y el resto de variables, utilizando un dataset público de Kaggle.\nAnálisis bidimensional y tridimensional de datos independientes y dependientes mediante tablas de contingencia."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Sobre mí",
    "section": "",
    "text": "¡Hola! Soy Eduardo Aragón Rueda, graduado en Estadística por la Universidad de Granada y actualmente me encuentro realizando el Máster en Técnicas Cuantitativas en Gestión Empresarial en la misma universidad.\nEste blog está realizado para una de las asignaturas de este máster, aunque gracias a su utilidad se irán introduciendo más proyectos que pueda ir realizando en un futuro y sean de interés.\nEn él encontraremos herramientas para realizar diversas técnicas estadísticas, como estadística descriptiva, inferencia o regresión lineal, mediante el lenguaje de programación R debido a su gran utilidad en este sector. Los contenidos que se muestran en el blog se realizarán sobre datos que puedan ser conseguidos desde R o desde mi Github, con el fin de que puedan replicarse sin ningún inconveniente.\n¡Muchas gracias por la visita!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Estadística en R",
    "section": "",
    "text": "Regresión lineal múltiple\n\n\n\nRegresión\n\nMúltiple\n\nMulticolinealidad\n\nNormalidad\n\nHomocedasticidad\n\n\n\nÁrboles y regresión\n\n\n\nEduardo Aragón\n\n\n28 ene 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\nInferencia\n\n\n\nInferencia\n\nANOVA\n\nTukey\n\nKruskal-Wallis\n\nMann-Whitney\n\nggplot2\n\n\n\nEsperanza de vida e Índice de Desarrollo Humano\n\n\n\nEduardo Aragón\n\n\n16 ene 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\nEstadística Descriptiva\n\n\n\nDescriptiva\n\nEstadisticos\n\nMedia\n\nMediana\n\nHistograma\n\nBoxplot\n\nVisualización\n\nDatos\n\n\n\nEstadística con pingüinos\n\n\n\nEduardo Aragón\n\n\n10 ene 2026\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "posts/inferencia/inferencia.html",
    "href": "posts/inferencia/inferencia.html",
    "title": "Inferencia",
    "section": "",
    "text": "A continuación se presenta una actividad de inferencia sobre un conjunto de datos, los cuales se encuentran depurados y listos para usar desde mi directorio de Github, aunque podremos usarlos directamente desde la consola de R, como veremos más adelante.\nLos datos con los que vamos a trabajar han sido obtenidos del Instituto Vasco de Estadística-Eustat y tratan sobre el Índice de Desarrollo Humano (IDH) para 193 países, pudiendo ver el formato original en el siguiente enlace: EUSTAT\nRespecto a la base de datos disponible en Eustat, nuestro archivo contiene una variable más relacionada con el nivel de desarrollo humano en lugar del propio índice. Eustat presenta en sus datos los países ordenados en función de si tienen un IDH muy alto, alto, medio y bajo. A partir de esta clasificación, se ha creado una variable cualitativa ordinal que representa a los países en función de dichas categorías.\nPodemos trabajar con estos datos de la siguiente manera, además de ver las variables.\n\ndatos&lt;-read.table(\"https://raw.githubusercontent.com/edus1807/Archivos_Quarto/refs/heads/main/renta_paises.txt\",header = T,sep=\";\")\nnames(datos)\n\n[1] \"País\"                          \"IDH\"                          \n[3] \"Esperanza_de_vida\"             \"Años_esperados_de_escolaridad\"\n[5] \"Años_promedio_escolaridad\"     \"Renta_nacional_bruta\"         \n[7] \"Desarrollo_humano\"            \n\nattach(datos)\n\nEl nombre de las variables es bastante claro respecto a lo que representa cada una de ellas, indicando solo que la variable Desarrollo_humano es la que ha sido creada por nosotros. También podemos ver como se encuentra organizado el propio fichero y los niveles que tiene la variable creada, mediante el siguiente código:\n\nhead(datos)\n\n       País   IDH Esperanza_de_vida Años_esperados_de_escolaridad\n1  Islandia 0.972            82.691                      18.85059\n2   Noruega 0.970            83.308                      18.79285\n3     Suiza 0.970            83.954                      16.66753\n4 Dinamarca 0.962            81.933                      18.70401\n5  Alemania 0.959            81.378                      17.30922\n6    Suecia 0.959            83.262                      18.99147\n  Años_promedio_escolaridad Renta_nacional_bruta Desarrollo_humano\n1                  13.90893             69116.94          MUY ALTO\n2                  13.11796            112710.02          MUY ALTO\n3                  13.94912             81948.90          MUY ALTO\n4                  13.02732             76007.86          MUY ALTO\n5                  14.29637             64053.22          MUY ALTO\n6                  12.74033             66102.09          MUY ALTO\n\nlevels(as.factor(Desarrollo_humano))\n\n[1] \"ALTO\"     \"BAJO\"     \"MEDIO\"    \"MUY ALTO\"\n\n\nA pesar de tener tantas variables, en este post solo nos centraremos en dos ellas, en la citada anteriormente Desarrollo_humano y en Esperanza_de_vida, puesto que nuestro objetivo será comprobar si la esperanza de vida puede considerarse igual en países con un distinto IDH. Para ello lo lógico sería pensar en un ANOVA, pues se trata de un caso de inferencia con más de dos poblaciones.\nPor tanto, la variable asociada a la esperanza de vida será nuestra variable dependiente, mientras que el factor Desarrollo_humano es la variable que define los grupos.\n\nAnálisis gráfico\nAntes de realizar la inferencia en si misma, podría ser útil ver como se comportan los datos en las cuatro categorías mediante un box-plot.\n\nlibrary(ggplot2)\n\nggplot(datos, aes(x = Desarrollo_humano, y = Esperanza_de_vida, fill = Desarrollo_humano)) + \n  stat_boxplot(geom = \"errorbar\",\n               width = 0.25) + \n  geom_boxplot()\n\n\n\n\n\n\n\n\nPodemos ver, antes de aplicar las técnicas que veremos más adelante, que sí parecen existir diferencias en la esperanza de vida en función del nivel de desarrollo humano. Concretamente vemos que aquellos países que tienen un IDH muy alto tienen más esperanza de vida que el resto, siguiendo un orden bastante descendiente en la esperanza cada vez que el IDH reduce su categoría. También se aprecia un valor atípico tanto para el desarrollo alto como medio.\n\n\nANOVA\nUna vez analizado el box-plot, es el momento de comprobar que se verifiquen las hipótesis básicas de este tipo de modelos.\nLo primero sería comprobar la independencia de las observaciones. En este caso vamos a asumir que los datos son independientes al tratarse de unidades nacionales distintas, sin entrar en debate de si un país depende de las características de sus vecinos, puesto se trata de un simple ejemplo.\nLa independencia de las observaciones se traduce a su vez en que los datos son aleatorios. Dicha aleatoriedad se podría comprobar mediante un test de rachas, pero en este caso no se considera pertinente. Los datos se encuentran ordenados en función de su IDH, por lo que seguro que dicho test va a detectar un patrón no aleatorio, rechazando así la aleatoriedad, lo cual no es un reflejo de la naturaleza de nuestros datos.\nPasamos a estudiar la homocedasticidad o igualdad de varianzas, puesto que para que se pueda usar el ANOVA la varianza en cada uno de los grupos debe ser significativamente igual. Para comprobarlo podemos plantear el siguiente contraste de hipótesis: \\[\n\\begin{cases}\nH_0: \\sigma^2_\\text{Muy Alto}=\\sigma^2_\\text{Alto}=\\sigma^2_\\text{Medio}=\\sigma^2_\\text{Bajo} \\\\\nH_1: \\sigma^2_\\text{Muy Alto}\\neq\\sigma^2_\\text{Alto}\\neq\\sigma^2_\\text{Medio}\\neq\\sigma^2_\\text{Bajo}\n\\end{cases}\n\\] Este contraste puede ser resuelto mediante el test de Levene, siendo la función que permite su uso leveneTest, la cual se encuentra dentro de la librería car. Para poder usarla es necesario previamente realizar el modelo ANOVA mediante aov.\n\nanova&lt;-aov(Esperanza_de_vida ~ Desarrollo_humano, data = datos)\nrequire(car)\n\nLoading required package: car\n\n\nLoading required package: carData\n\nleveneTest(anova,center=mean)\n\nWarning in leveneTest.default(y = y, group = group, ...): group coerced to\nfactor.\n\n\nLevene's Test for Homogeneity of Variance (center = mean)\n       Df F value Pr(&gt;F)\ngroup   3  0.2346 0.8722\n      189               \n\n\nObtenemos que el p-valor=0.8722 es mayor que un nivel de significación \\(\\alpha\\)=0.05, por lo que no tenemos evidencias estadísticas para rechazar la hipótesis nula anterior. Por tanto, podemos considerar las varianzas iguales con una significación del 5%.\nPor último, nos queda verificar si se cumple el supuesto de normalidad, donde los datos de cada grupo deben seguir de manera aproximada dicha distribución. Esto se puede comprobar de manera analítica mediante el test de Shapiro-Wilks o Kolmogorov-Smirnov (con la corrección de Lilliefors pues se trata de normalidad) o de manera visual con algún gráfico como un QQ-plot.\nEl uso de estos test suele medirse en función del tamaño de la muestra, siendo recomendado el uso de Shapiro-Wilks con tamaños menores de 50 unidades y K-S-Lilliefors en caso contrario. Los tamaños de cada nivel son:\n\nby(datos$Esperanza_de_vida,datos$Desarrollo_humano,length)\n\ndatos$Desarrollo_humano: ALTO\n[1] 50\n------------------------------------------------------------ \ndatos$Desarrollo_humano: BAJO\n[1] 26\n------------------------------------------------------------ \ndatos$Desarrollo_humano: MEDIO\n[1] 43\n------------------------------------------------------------ \ndatos$Desarrollo_humano: MUY ALTO\n[1] 74\n\n\nIgualmente por comodidad podemos usar ambos en cada nivel y comparar resultados.\n\nlibrary(\"nortest\")\nby(datos$Esperanza_de_vida,datos$Desarrollo_humano,lillie.test)\n\ndatos$Desarrollo_humano: ALTO\n\n    Lilliefors (Kolmogorov-Smirnov) normality test\n\ndata:  dd[x, ]\nD = 0.07324, p-value = 0.7218\n\n------------------------------------------------------------ \ndatos$Desarrollo_humano: BAJO\n\n    Lilliefors (Kolmogorov-Smirnov) normality test\n\ndata:  dd[x, ]\nD = 0.12845, p-value = 0.3286\n\n------------------------------------------------------------ \ndatos$Desarrollo_humano: MEDIO\n\n    Lilliefors (Kolmogorov-Smirnov) normality test\n\ndata:  dd[x, ]\nD = 0.070556, p-value = 0.8532\n\n------------------------------------------------------------ \ndatos$Desarrollo_humano: MUY ALTO\n\n    Lilliefors (Kolmogorov-Smirnov) normality test\n\ndata:  dd[x, ]\nD = 0.14025, p-value = 0.001012\n\nby(datos$Esperanza_de_vida,datos$Desarrollo_humano,shapiro.test)\n\ndatos$Desarrollo_humano: ALTO\n\n    Shapiro-Wilk normality test\n\ndata:  dd[x, ]\nW = 0.97673, p-value = 0.4236\n\n------------------------------------------------------------ \ndatos$Desarrollo_humano: BAJO\n\n    Shapiro-Wilk normality test\n\ndata:  dd[x, ]\nW = 0.96422, p-value = 0.4812\n\n------------------------------------------------------------ \ndatos$Desarrollo_humano: MEDIO\n\n    Shapiro-Wilk normality test\n\ndata:  dd[x, ]\nW = 0.96394, p-value = 0.193\n\n------------------------------------------------------------ \ndatos$Desarrollo_humano: MUY ALTO\n\n    Shapiro-Wilk normality test\n\ndata:  dd[x, ]\nW = 0.94967, p-value = 0.005151\n\n\nVemos que con ambos test, el p-valor asociado al nivel de IDH muy alto es menor que un nivel de significación \\(\\alpha\\)=0.05, por lo que tendríamos evidencias estadísticas para rechazar la normalidad en ese grupo. Lo vemos visualmente también:\n\nggplot(datos, aes(sample = Esperanza_de_vida)) +\n  stat_qq() +\n  stat_qq_line() +\n  facet_wrap(~Desarrollo_humano) +\n  labs(title = \"Gráfico Q-Q de Esperanza de vida por Desarrollo humano\")\n\n\n\n\n\n\n\n\nVemos que en MUY ALTO, a partir del valor 0 del eje de abscisas los valores se alejan de la diagonal teórica formando una especie de curva sobre ella. Esto es claramente un indicio de falta de normalidad en dicho nivel como pudimos comprobar anteriormente.\nAnte esta situación se pueden valorar dos posibles opciones. Una es continuar empleando el ANOVA pues, aunque la normalidad no se verifica en uno de los niveles del factor, es una prueba bastante robusta a la falta de la misma cuando el tamaño de la muestra es grande (MUY ALTO tenía 74 países) y además, se verifica la homocedasticidad.\nSin embargo, si somos más rigurosos otra opción sería el uso de un enfoque no paramétrico, empleando el test de Kruskal-Wallis pues uno de los supuestos no se verifica.\nEn consecuencia, se aplicarán ambos procedimientos (ANOVA y Kruskal–Wallis) con el objetivo de comprobar la robustez de los resultados, observándose que las conclusiones obtenidas son consistentes entre ambos enfoques.\nSe plantea el contraste de hipótesis de igualdad de medias para el ANOVA y se muestra su salida en R:\n\\[\n  \\begin{cases}\nH_0: \\mu_\\text{Muy Alto}=\\mu_\\text{Alto}=\\mu_\\text{Medio}=\\mu_\\text{Bajo}\\\\\nH_1: \\mu_\\text{Muy Alto}\\neq\\mu_\\text{Alto}\\neq\\mu_\\text{Medio}\\neq\\mu_\\text{Bajo}\n\\end{cases}\n\\]\n\nsummary(anova)\n\n                   Df Sum Sq Mean Sq F value Pr(&gt;F)    \nDesarrollo_humano   3   7096  2365.5   161.8 &lt;2e-16 ***\nResiduals         189   2764    14.6                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nObtenemos que el p-valor es menor que 0.05, por lo que tendríamos evidencias estadísticas para rechazar que las medias sean iguales. En ese caso habría que comprobar entre que niveles existen esas diferencias aplicando un test de comparaciones múltiples como Tukey.\n\nTukeyHSD(anova)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = Esperanza_de_vida ~ Desarrollo_humano, data = datos)\n\n$Desarrollo_humano\n                    diff        lwr       upr    p adj\nBAJO-ALTO      -9.733709 -12.130267 -7.337151 0.00e+00\nMEDIO-ALTO     -5.520277  -7.581738 -3.458816 0.00e+00\nMUY ALTO-ALTO   6.700925   4.886400  8.515449 0.00e+00\nMEDIO-BAJO      4.213432   1.751044  6.675820 9.14e-05\nMUY ALTO-BAJO  16.434634  14.174937 18.694332 0.00e+00\nMUY ALTO-MEDIO 12.221202  10.320580 14.121824 0.00e+00\n\n\nEn todas las comparaciones se obtiene un p-valor significativo, pues este es menor a cualquier nivel de significación arbitrario. Esto se traduce en que todos los niveles son significativamente distintos entre sí. Por poner un ejemplo, podemos decir que los países con IDH muy alto presentan 6.7 años más de esperanza de vida que aquellos con IDH alto, mientras que con el resto de resultados podríamos decir que a medida que aumenta el IDH se produce un aumento de la esperanza de vida.\n\n\nKruskal-Wallis\nComo se indicó anteriormente, puesto que la normalidad de uno de los niveles no se cumplía, una opción sería analizar las diferencias mediante un enfoque no paramétrico, empleando en este caso el test de Kruskal-Wallis. Planteamos el contraste en función de las medianas: \\[\n  \\begin{cases}\nH_0: Med(\\text{Muy alto})= Med(\\text{Alto})=Med(\\text{Medio})= Med(\\text{Bajo}) \\\\\nH_1:  Med(\\text{Muy alto})\\neq Med(\\text{Alto})\\neq Med(\\text{Medio})\\neq Med(\\text{Bajo})\n\\end{cases}\n\\]\nPara resolverlo aplicamos el siguiente código:\n\nkruskal.test(Esperanza_de_vida ~ Desarrollo_humano, data = datos)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  Esperanza_de_vida by Desarrollo_humano\nKruskal-Wallis chi-squared = 141.39, df = 3, p-value &lt; 2.2e-16\n\n\nObtenemos que el p-valor es menor que 0.05, por lo que tendríamos evidencias estadísticas para rechazar que las medianas sean iguales. En ese caso habría que comprobar entre que niveles existen esas diferencias aplicando un test como Mann-Whitney con la corrección de Bonferroni.\n\npairwise.wilcox.test(Esperanza_de_vida,Desarrollo_humano,p.adjust.method = \"bonferroni\")\n\n\n    Pairwise comparisons using Wilcoxon rank sum test with continuity correction \n\ndata:  Esperanza_de_vida and Desarrollo_humano \n\n         ALTO    BAJO    MEDIO  \nBAJO     1.6e-10 -       -      \nMEDIO    2.5e-07 0.00061 -      \nMUY ALTO 5.2e-13 2.5e-13 &lt; 2e-16\n\nP value adjustment method: bonferroni \n\n\nVemos que todos los p-valores son menores que 0.05, por lo que podemos decir que existen diferencias significativas entre todos los niveles del IDH en función de la esperanza de vida.\n\n\nConclusiones\nPor tanto, independientemente del enfoque, tomado obtenemos que existen diferencias significativas entre los niveles del Índice de Desarrollo Humano en función de la esperanza de vida, siendo esta cada vez mayor a medida que aumenta el propio IDH."
  }
]